{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desig Applications with Geometric Deep Learning\n",
    "\n",
    "In this set of examples the objective is to illustrate how the trained PC-AE and -VAE can be utilized as shape-generative models in different applications. Since the application is highly dependent on the objectves of the user, we will focus on two general cases of shape that could be inserted within an automated framework for design optimization.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Design Interpolation using Latent Variables\n",
    "\n",
    "In this first example we generate shapes by interpolating the latent representations of three car shapes. The autoencoder was trained on the car class of ShapeNetCore, sampled with the shrink-wrapping algorithm, and the latent space is 128-dimensional.\n",
    "\n",
    "We perform the interpolation according to the following steps:\n",
    "\n",
    "1. Load the necessary libraries\n",
    "2. Load the latent representations of the shapes used for training the PC-AE\n",
    "3. Select three random representations ($Z_1$, $Z_2$, $Z_3$)\n",
    "4. Linear interpolation between ($Z_1$, $Z_2$) and ($Z_2$, $Z_3$)\n",
    "5. Generate the batch of interpolated shapes\n",
    "6. Visualize the interpolated shapes\n",
    "\n",
    "The proposed algorithm is equivalent to the following script in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Class for operating with the trained networks\n",
    "from gdl4designapps.designapps import DesignApps\n",
    "# Class for visualizing geometric data\n",
    "from gdl4designapps.designapps import Vis3D\n",
    "\n",
    "## Load learned latent representations\n",
    "data_pc_ae = np.array(pd.read_csv(\"test_pc-ae/network_verification/network_verification.dat\"))\n",
    "# Select data samples\n",
    "# !! Tip !!: You can also change the first index of `data_pc_ae` to interpolate other shapes\n",
    "Z_1 = data_pc_ae[9, 1:129].astype(float)\n",
    "Z_2 = data_pc_ae[73, 1:129].astype(float)\n",
    "Z_3 = data_pc_ae[3105, 1:129].astype(float)\n",
    "\n",
    "## Interpolate the latent representations\n",
    "# Step size\n",
    "interp_steps = np.linspace(0,1,5)\n",
    "# Array to store the interpolated representations\n",
    "Zint = np.zeros((interp_steps.shape[0]*2,128,1))\n",
    "# Interpolation between Z_1 and Z_2\n",
    "for i in range(interp_steps.shape[0]):\n",
    "    Zint[i,:,0] = Z_1 + interp_steps[i]*(Z_2-Z_1)\n",
    "# Interpolation between Z_2 and Z_3\n",
    "for i in range(interp_steps.shape[0]):\n",
    "    Zint[i+interp_steps.shape[0],:,0] = Z_2 + interp_steps[i]*(Z_3-Z_2)\n",
    "    \n",
    "## Reconstruct the 3Dpoint clouds\n",
    "sess, S_in, Z, S_out, feat_layer, pc_size,\\\n",
    "dpout, gamma_n, latt_def, flags = DesignApps.import_net_graph(\n",
    "                                        'pcae_training_config.py', GPUid=-1)\n",
    "pcs = DesignApps.Z_to_pointcloud('pcae_training_config.py', sess, S_out, Z,\n",
    "                                Zint, flags, dpout=None, gamma_n=None, latt_def=None, GPUid=-1)[0]\n",
    "\n",
    "# Concatenate point clouds to ease the visualization\n",
    "pcs_concat = np.array(np.reshape(pcs, (-1,3)))\n",
    "for j in range(pcs.shape[0]):\n",
    "    pcs_concat[j*pcs.shape[1]:(j+1)*pcs.shape[1],:] = pcs[j,:,:] + [0, j*2.2, 0]\n",
    "\n",
    "# Shape visualization\n",
    "Vis3D.pcplot(pcs_concat*[-1,-1,1], figname=\"test_pc-ae/network_verification/pc_interpolation\", colorpoints=\"#c8102e\", cam_az=15, cam_el=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization shows the interpolated shapes from $Z_1$ (right) to $Z_2$ (middle) and finally to $Z_3$ (left). The size, colors and position of the camera can be changed either by manipulating the input parameters of the ``pcplot`` function or by enabling the interactive version of pyvista (check out [ipyvtklink](https://docs.pyvista.org/user-guide/jupyter/ipyvtk_plotting.html))\n",
    "\n",
    "This is a standard example of how the function ``Z_to_pointcloud`` can be utilized to generate 3D point clouds from the random representations sampled from the latent space. In practice, optimization algorithms do not necessarily interpolate representations, but search the optimal combination of values for the latent features. Hence, ``Z_to_pointcloud`` can be added to optimization pipelines as shape-generative function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point2FFD: Generating polygonal meshes\n",
    "\n",
    "Template meshes with different sizes cannot be easily concatenated into a single tensor\n",
    "\n",
    "Process: Input (3D PC, Z) --> Lattice deformation --> FFD to mesh of interest\n",
    "\n",
    "STL files cannot be added to the repo, ID of the shapes utilized in the paper\n",
    "\n",
    "```\n",
    "Code \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Transfer of Selected Features\n",
    "\n",
    "In this second example, we generate shapes by transferring specific features. We utilize this resource in our [multi-task framework](https://ieeexplore.ieee.org/abstract/document/9446541) in order to foster common geometric features in the optimized designs. In order to transfer the features, we utilize the following algorithm:\n",
    "\n",
    "1. Load the necessary libraries (in this jupyter notebook, the libraries were loaded in the previous step)\n",
    "2. Select two shapes ($S_0$, $S_1$)\n",
    "3. Visualize the learned features\n",
    "4. Generate the corresponding latent representations for the shapes\n",
    "5. Exchange features between latent representations ($Z_0$ $\\rightarrow$ $S_1$)\n",
    "6. Reconstruct the 3D point clouds\n",
    "\n",
    "The described algorithm is equivalent to the following script in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the 3D point clouds\n",
    "# in this case, we utilize the first and last interpolated shapes\n",
    "pcs_initial = pcs[[0,pcs.shape[0]-1],:,:]\n",
    "\n",
    "## Visualize the latent features\n",
    "# In this case, we pre-visualized the features and display here the ones the map the rear of the car shapes.\n",
    "feat_rear = [0, 8, 9, 10, 11, 12, 14, 15, 22, 53]\n",
    "print(\"Selected features\")\n",
    "feat_batch = DesignApps.featvis(\"pcae_training_config.py\", sess, S_in,\n",
    "                                feat_layer, pcs_initial, flags, \n",
    "                                dpout=None, gamma_n=None, GPUid=-1, plot=True)\n",
    "\n",
    "## Generate latent representations\n",
    "Z_batch = DesignApps.pointcloud_to_Z(\"pcae_training_config.py\", sess, S_in, Z,\n",
    "                                    pcs_initial, flags,\n",
    "                                    dpout=None, gamma_n=None, GPUid=-1)\n",
    "\n",
    "## Transfer latent features from Z_0 to Z_1\n",
    "Z_transfer = np.array(Z_batch[[1,],:,:])\n",
    "Z_transfer[0,feat_rear,:] = Z_batch[0, feat_rear,:]\n",
    "\n",
    "## Reconstruct Point cloud\n",
    "pc_transfer = DesignApps.Z_to_pointcloud(\"pcae_training_config.py\", sess,\n",
    "                                         S_out, Z, Z_transfer, flags, dpout=None, gamma_n=None, \n",
    "                                         latt_def=None, GPUid=-1)[0][0]\n",
    "\n",
    "## Visualize point clouds\n",
    "print(\"Initial Shape\")\n",
    "Vis3D.pcplot(pcs_initial[1,:,:], figname=\"test_pc-ae/network_verification/pc_transfer_before\", colorpoints=\"#00334c\", cam_az=90, cam_el=0)\n",
    "print(\"Shape with targeted features\")\n",
    "Vis3D.pcplot(pcs_initial[0,:,:], figname=\"test_pc-ae/network_verification/pc_transfer_target\", colorpoints=\"#959da8\", cam_az=90, cam_el=0)\n",
    "print(\"Shape with transferred features\")\n",
    "Vis3D.pcplot(pc_transfer, figname=\"test_pc-ae/network_verification/pc_transfer_after\", colorpoints=\"#c8102e\", cam_az=90, cam_el=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
